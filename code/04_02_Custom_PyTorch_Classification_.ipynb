{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 TEST CUSTOM CLEAN FOR PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "      <th>is_indian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0 Earthquake</td>\n",
       "      <td>As a series of minor earthquakes start tearing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12 Rounds (film)</td>\n",
       "      <td>A sting operation to capture arms dealer Miles...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12 Rounds 3: Lockdown</td>\n",
       "      <td>Detective Tyler Burke  and his two men infiltr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200 mph</td>\n",
       "      <td>When the older brother (Tommy Nash) he idolize...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ablaze (2001 film)</td>\n",
       "      <td>Andrew Thomas is an agent tasked with recordin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>Choked (film)</td>\n",
       "      <td>Sarita Pillai and Sushant Pillai are a married...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>Chumbak</td>\n",
       "      <td>Chumbak is a coming-of-age story of Baalu, a t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>Chungakkarum Veshyakalum</td>\n",
       "      <td>Chungakkarum Veshyakalum is the story of a Mal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>Chuzhi</td>\n",
       "      <td>Varghese is a planter who lives with his wife ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>Cinema Paithiyam</td>\n",
       "      <td>Jaya is a cinephile. So obsessed is she with c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title  \\\n",
       "0              10.0 Earthquake   \n",
       "1             12 Rounds (film)   \n",
       "2        12 Rounds 3: Lockdown   \n",
       "3                      200 mph   \n",
       "4           Ablaze (2001 film)   \n",
       "...                        ...   \n",
       "3995             Choked (film)   \n",
       "3996                   Chumbak   \n",
       "3997  Chungakkarum Veshyakalum   \n",
       "3998                    Chuzhi   \n",
       "3999          Cinema Paithiyam   \n",
       "\n",
       "                                                   plot  is_indian  \n",
       "0     As a series of minor earthquakes start tearing...          0  \n",
       "1     A sting operation to capture arms dealer Miles...          0  \n",
       "2     Detective Tyler Burke  and his two men infiltr...          0  \n",
       "3     When the older brother (Tommy Nash) he idolize...          0  \n",
       "4     Andrew Thomas is an agent tasked with recordin...          0  \n",
       "...                                                 ...        ...  \n",
       "3995  Sarita Pillai and Sushant Pillai are a married...          1  \n",
       "3996  Chumbak is a coming-of-age story of Baalu, a t...          1  \n",
       "3997  Chungakkarum Veshyakalum is the story of a Mal...          1  \n",
       "3998  Varghese is a planter who lives with his wife ...          1  \n",
       "3999  Jaya is a cinephile. So obsessed is she with c...          1  \n",
       "\n",
       "[4000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/merged_plots.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "(0, 'As a series of minor earthquakes start tearing apart Los Angeles, scientist Emily of the USGS theorizes that it is all building to a super quake that will drop the entire city into a lava-filled chasm. Engineer Jack whose daughter has gone camping with her friends in the danger area and whose company is responsible for the quakes due to their deep fracking feels obligated to help, and races with Emily through the increasingly damaged city with the hopes of diverting the epicenter to Long Beach and potentially saving millions of lives in the city of Los Angeles.')\n",
      "(1, 'Jaya is a cinephile. So obsessed is she with cinema, that she worships the popular actor Jaishankar, believing all that he portrays on screen, to be his real self. He becomes the ideal man of her dreams, and she even tattoos his name in her arm. Hell breaks loose when she refuses to marry Natarajan, the boy arranged by her brother and her sister-in-law. At his juncture, steps in her uncle, who takes it upon himself to show her the true world, by taking her on a trip around the real life of a star.')\n"
     ]
    }
   ],
   "source": [
    "value_tuples = []\n",
    "for row in df.iterrows():\n",
    "    values = row[1]\n",
    "    value_tuples.append((values['is_indian'], values['plot']))\n",
    "\n",
    "print(len(value_tuples))\n",
    "print(value_tuples[0])\n",
    "print(value_tuples[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: 2800\n",
      "testing size: 1200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_value_tuples, test_value_tuples = train_test_split(value_tuples, test_size=0.3, shuffle=True, random_state=0)\n",
    "\n",
    "print('training size:', len(train_value_tuples))\n",
    "print('testing size:', len(test_value_tuples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data processing pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter_stemmer=PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "non_name_words = set(nltk.corpus.words.words())\n",
    "\n",
    "def clean(text):\n",
    "\n",
    "    # lowercasing\n",
    "    text = text.lower()\n",
    "\n",
    "    # removing special characters\n",
    "    text = re.sub('\\\\W', ' ', text)\n",
    "\n",
    "    # splitting into tokens\n",
    "    words = text.split()\n",
    "\n",
    "    # removing stopwords\n",
    "    filtered_words = []\n",
    "    for word in words:\n",
    "        if not word in stop_words:\n",
    "            filtered_words.append(word)\n",
    "    \n",
    "    # word stemming\n",
    "    stemmed_words = [porter_stemmer.stem(word) for word in filtered_words]\n",
    "    \n",
    "    # removing names\n",
    "    result = []\n",
    "    for word in stemmed_words:\n",
    "        if word in non_name_words:\n",
    "            result.append(word)\n",
    "      \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "\n",
    "    def __init__(self, touples):\n",
    "        self.vocab = {}\n",
    "        i = 1\n",
    "        for _, text in touples:\n",
    "            for word in clean(text):\n",
    "                if not word in self.vocab:\n",
    "                    self.vocab[word] = i\n",
    "                    i += 1\n",
    "\n",
    "    def getValues(self, words):\n",
    "        values = []\n",
    "        for word in words:\n",
    "            if word in self.vocab:\n",
    "                values.append(self.vocab[word]) \n",
    "            else:\n",
    "                # use 0 if word is not part of the vocabulary\n",
    "                values.append(0)\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = Vocabulary(value_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw: So obsessed is she with cinema, that she worships the popular actor Jaishankar\n",
      "cleaned: ['obsess', 'cinema', 'worship', 'popular', 'actor']\n",
      "bow: [1221, 6674, 3391, 805, 3020]\n",
      "\n",
      "vocab length: 8885\n"
     ]
    }
   ],
   "source": [
    "# # Named entities, stop words and punctuation are NOT part of the vocabulary\n",
    "\n",
    "example_text = 'So obsessed is she with cinema, that she worships the popular actor Jaishankar'\n",
    "print('raw:',example_text)\n",
    "print('cleaned:',clean(example_text))\n",
    "print('bow:',vocabulary.getValues(clean(example_text)))\n",
    "print('\\nvocab length:', len(vocabulary.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocabulary.getValues(clean(x))\n",
    "\n",
    "# label pipeline does not have to do anything since values are already 0 or 1\n",
    "label_pipeline = lambda x: int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1474, 176, 478, 143, 927, 430]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline('At his juncture, steps in her uncle, who takes it upon himself to show her the true world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pipeline(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data batch and iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brand\\AppData\\Local\\Temp\\ipykernel_13932\\147827112.py:2: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:77.)\n",
      "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "         label_list.append(label_pipeline(_label))\n",
    "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "         text_list.append(processed_text)\n",
    "         offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate an Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_value_tuples)\n",
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocabulary.vocab)\n",
    "emsize = 64\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for evaluation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, offsets)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 24.70s | valid accuracy    0.729 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time: 24.26s | valid accuracy    0.857 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time: 25.47s | valid accuracy    0.857 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time: 28.35s | valid accuracy    0.893 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time: 29.06s | valid accuracy    0.893 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time: 27.45s | valid accuracy    0.900 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time: 30.00s | valid accuracy    0.907 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time: 27.05s | valid accuracy    0.900 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time: 30.49s | valid accuracy    0.907 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time: 31.04s | valid accuracy    0.914 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 3  # learning rate\n",
    "BATCH_SIZE = 64 # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "\n",
    "train_iter = iter(train_value_tuples)\n",
    "test_iter = iter(test_value_tuples)\n",
    "\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "      scheduler.step()\n",
    "    else:\n",
    "       total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected i < index_size to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\brand\\OneDrive - FH Technikum Wien\\05_WS2022\\CVNLP\\00_Other\\nlp_project\\NLP-on-Movie-Plots\\code\\04_02_Custom_PyTorch_Classification_.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brand/OneDrive%20-%20FH%20Technikum%20Wien/05_WS2022/CVNLP/00_Other/nlp_project/NLP-on-Movie-Plots/code/04_02_Custom_PyTorch_Classification_.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mChecking the results of test dataset.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/brand/OneDrive%20-%20FH%20Technikum%20Wien/05_WS2022/CVNLP/00_Other/nlp_project/NLP-on-Movie-Plots/code/04_02_Custom_PyTorch_Classification_.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m accu_test \u001b[39m=\u001b[39m evaluate(test_dataloader)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/brand/OneDrive%20-%20FH%20Technikum%20Wien/05_WS2022/CVNLP/00_Other/nlp_project/NLP-on-Movie-Plots/code/04_02_Custom_PyTorch_Classification_.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtest accuracy \u001b[39m\u001b[39m{:8.3f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(accu_test))\n",
      "\u001b[1;32mc:\\Users\\brand\\OneDrive - FH Technikum Wien\\05_WS2022\\CVNLP\\00_Other\\nlp_project\\NLP-on-Movie-Plots\\code\\04_02_Custom_PyTorch_Classification_.ipynb Cell 25\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(dataloader)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/brand/OneDrive%20-%20FH%20Technikum%20Wien/05_WS2022/CVNLP/00_Other/nlp_project/NLP-on-Movie-Plots/code/04_02_Custom_PyTorch_Classification_.ipynb#X33sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/brand/OneDrive%20-%20FH%20Technikum%20Wien/05_WS2022/CVNLP/00_Other/nlp_project/NLP-on-Movie-Plots/code/04_02_Custom_PyTorch_Classification_.ipynb#X33sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mfor\u001b[39;00m idx, (label, text, offsets) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/brand/OneDrive%20-%20FH%20Technikum%20Wien/05_WS2022/CVNLP/00_Other/nlp_project/NLP-on-Movie-Plots/code/04_02_Custom_PyTorch_Classification_.ipynb#X33sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         predicted_label \u001b[39m=\u001b[39m model(text, offsets)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/brand/OneDrive%20-%20FH%20Technikum%20Wien/05_WS2022/CVNLP/00_Other/nlp_project/NLP-on-Movie-Plots/code/04_02_Custom_PyTorch_Classification_.ipynb#X33sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         loss \u001b[39m=\u001b[39m criterion(predicted_label, label)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/brand/OneDrive%20-%20FH%20Technikum%20Wien/05_WS2022/CVNLP/00_Other/nlp_project/NLP-on-Movie-Plots/code/04_02_Custom_PyTorch_Classification_.ipynb#X33sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         total_acc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (predicted_label\u001b[39m.\u001b[39margmax(\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m label)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\brand\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\brand\\OneDrive - FH Technikum Wien\\05_WS2022\\CVNLP\\00_Other\\nlp_project\\NLP-on-Movie-Plots\\code\\04_02_Custom_PyTorch_Classification_.ipynb Cell 25\u001b[0m in \u001b[0;36mTextClassificationModel.forward\u001b[1;34m(self, text, offsets)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/brand/OneDrive%20-%20FH%20Technikum%20Wien/05_WS2022/CVNLP/00_Other/nlp_project/NLP-on-Movie-Plots/code/04_02_Custom_PyTorch_Classification_.ipynb#X33sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, text, offsets):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/brand/OneDrive%20-%20FH%20Technikum%20Wien/05_WS2022/CVNLP/00_Other/nlp_project/NLP-on-Movie-Plots/code/04_02_Custom_PyTorch_Classification_.ipynb#X33sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding(text, offsets)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/brand/OneDrive%20-%20FH%20Technikum%20Wien/05_WS2022/CVNLP/00_Other/nlp_project/NLP-on-Movie-Plots/code/04_02_Custom_PyTorch_Classification_.ipynb#X33sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(embedded)\n",
      "File \u001b[1;32mc:\\Users\\brand\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\brand\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:387\u001b[0m, in \u001b[0;36mEmbeddingBag.forward\u001b[1;34m(self, input, offsets, per_sample_weights)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, offsets: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, per_sample_weights: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    357\u001b[0m     \u001b[39m\"\"\"Forward pass of EmbeddingBag.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[39m          returned vectors filled by zeros.\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 387\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding_bag(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, offsets,\n\u001b[0;32m    388\u001b[0m                            \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type,\n\u001b[0;32m    389\u001b[0m                            \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse,\n\u001b[0;32m    390\u001b[0m                            per_sample_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minclude_last_offset,\n\u001b[0;32m    391\u001b[0m                            \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx)\n",
      "File \u001b[1;32mc:\\Users\\brand\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2392\u001b[0m, in \u001b[0;36membedding_bag\u001b[1;34m(input, weight, offsets, max_norm, norm_type, scale_grad_by_freq, mode, sparse, per_sample_weights, include_last_offset, padding_idx)\u001b[0m\n\u001b[0;32m   2385\u001b[0m \u001b[39mif\u001b[39;00m per_sample_weights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m mode \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msum\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   2386\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   2387\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39membedding_bag: per_sample_weights was not None. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mper_sample_weights is only supported for mode=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2389\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(got mode=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m). Please open a feature request on GitHub.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(mode)\n\u001b[0;32m   2390\u001b[0m     )\n\u001b[1;32m-> 2392\u001b[0m ret, _, _, _ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49membedding_bag(\n\u001b[0;32m   2393\u001b[0m     weight, \u001b[39minput\u001b[39;49m, offsets, scale_grad_by_freq, mode_enum, sparse, per_sample_weights, include_last_offset, padding_idx\n\u001b[0;32m   2394\u001b[0m )\n\u001b[0;32m   2395\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected i < index_size to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)"
     ]
    }
   ],
   "source": [
    "print('Checking the results of test dataset.')\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69a9235b2799f09bc7a4d7fc4018927df298a0a697379818c8dec9478f72590e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
